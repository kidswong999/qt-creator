<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>MobileNetV1</title>
</head>
<body>
<h2><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md">MobileNetV1</a></h2>
<p><a href="https://arxiv.org/abs/1704.04861">MobileNets</a> are small, low-latency, low-power models parameterized to meet the resource constraints of a variety of use cases. They can be built upon for classification, detection, embeddings and segmentation similar to how other popular large scale models, such as Inception, are used. MobileNets can be run efficiently on mobile devices with <a href="https://github.com/tensorflow/tflite-micro">TensorFlow Lite for Microcontrollers.</a></p>
<p>MobileNets trade off between latency, size and accuracy while comparing favorably with popular models from the literature.</p>
<p>Choose the right MobileNet model to fit your latency and size budget. The size of the network in memory and on disk is proportional to the number of parameters. The latency and power usage of the network scales with the number of Multiply-Accumulates (MACs) which measures the number of fused Multiplication and Addition operations. These MobileNet models have been trained on the <a href="http://www.image-net.org/challenges/LSVRC/2012/">ILSVRC-2012-CLS</a> image classification dataset. Accuracies were computed by evaluating using a single image crop.</a>
</body>
</html>
